{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "258ac4f6-647e-47ad-9e25-31dc4c605542",
   "metadata": {},
   "source": [
    "# NLP WITH MACHINE LEARNING\n",
    "## NLTK-1(WORD,SENTENCE,TOKENIZATION,REGREX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50880f20-9fb2-4a44-8cb5-4059507c65ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4c34b0-8339-4994-a400-a5a67d65a24a",
   "metadata": {},
   "source": [
    "#### (NLTK) is one of the largest Python libraries for performing various Natural Language Processing tasks. From rudimentary tasks such as text pre-processing to tasks like vectorized representation of text – NLTK’s API has covered everything\n",
    "\n",
    "### Tokenization\r",
    "    \n",
    "Tokenization refers to break down the text into smaller units. It entails splitting paragraphs into sentences and sentences into words. It is one of the initial steps of any NLP pipeline. Let us have a look at the two major kinds of tokenization that NLTK provides:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abb8277-0681-4956-8c67-dbc54e2124ec",
   "metadata": {},
   "source": [
    "# word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0726101-8dc6-4c0b-acb1-c6cff79454af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39c623a7-22ef-40c7-a281-49f2a384b405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'study', 'Machine', 'Learning', 'on', 'GeeksforGeeks', '.']\n"
     ]
    }
   ],
   "source": [
    "#define ur text or import from other source\n",
    "text = 'I study Machine Learning on GeeksforGeeks.' \n",
    "print(word_tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f0422-abdd-4ab5-9d58-ab4a8f6b839e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bde9622-5c68-42aa-a092-0b25a58b29c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GeeksforGeeks', 'is', 'a', 'great', 'learning', 'platform.It', 'is', 'one', 'of', 'the', 'best', 'for', 'Computer', 'Science', 'students', '.']\n",
      "['GeeksforGeeks is a great learning platform.It is one of the best for Computer Science students.']\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "sent = \"GeeksforGeeks is a great learning platform.\\\n",
    "It is one of the best for Computer Science students.\"\n",
    "print(word_tokenize(sent))\n",
    "print(sent_tokenize(sent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df85d6fc-a8d4-4f90-9cf5-d786ec580211",
   "metadata": {},
   "source": [
    "# REGULAR EXPRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbee61a3-d1cb-4c3b-bba2-f5c39193e8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1cb0bfd-8e91-4c9a-aa5c-2035712f41ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "text = \"NLP is fun and Can deal with texts and sounds, but can't deal with images. We have session at 11AM!.We can earn lot of $\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c9ff2c6-c991-4c5e-936a-1a14905366fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is',\n",
       " 'fun',\n",
       " 'and',\n",
       " 'an',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'texts',\n",
       " 'and',\n",
       " 'sounds',\n",
       " 'but',\n",
       " 'can',\n",
       " 't',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'images',\n",
       " 'e',\n",
       " 'have',\n",
       " 'session',\n",
       " 'at',\n",
       " 'e',\n",
       " 'can',\n",
       " 'earn',\n",
       " 'lot',\n",
       " 'of']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print word by word that contains all small case and starts from samll a to z\n",
    "regexp_tokenize(text,\"[a-z]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c574a25-f6a0-4188-b448-dfbc91c0c2c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['is',\n",
       " 'fun',\n",
       " 'and',\n",
       " 'an',\n",
       " 'deal',\n",
       " 'with',\n",
       " 'texts',\n",
       " 'and',\n",
       " 'sounds',\n",
       " 'but',\n",
       " \"can't\",\n",
       " 'deal',\n",
       " 'with',\n",
       " 'images',\n",
       " 'e',\n",
       " 'have',\n",
       " 'session',\n",
       " 'at',\n",
       " 'e',\n",
       " 'can',\n",
       " 'earn',\n",
       " 'lot',\n",
       " 'of']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extra quote ' get's you word like can't, don't\n",
    "regexp_tokenize(text,\"[a-z']+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c45a6804-6c9a-4e98-ac48-4b94e81ca7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP', 'C', 'W', 'AM', 'W']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # Print word by word that contains all caps and from caps A to Z\n",
    "regexp_tokenize(text,\"[A-Z]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "914b474e-317a-4602-b797-d59d5aed2847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"NLP is fun and Can deal with texts and sounds, but can't deal with images. We have session at 11AM!.We can earn lot of $\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EVERY THING IN ONE LINE\n",
    "regexp_tokenize(text,\"[\\a-z']+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b11f4f3-3505-4ed4-a9f8-c82273660df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NLP ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' C',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ', ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " '. W',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' 11AM!.W',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' ',\n",
       " ' $']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Anything starts with caret is not equal. \n",
    "regexp_tokenize(text,\"[^a-z']+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5488923-5f63-4644-af58-31b8489f9565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only numbers\n",
    "regexp_tokenize(text,\"[0-9]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6836efd-61bc-4b61-a19e-e3724b668a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"NLP is fun and Can deal with texts and sounds, but can't deal with images. We have session at \",\n",
       " 'AM!.We can earn lot of $']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Without numbers\n",
    "regexp_tokenize(text,\"[^0-9]+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed43d5e1-3c77-415a-9378-8344c1625641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['$']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tokenize(text,\"[$]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca90a8f1-471b-4cff-8e99-55ba3e120dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
